name: dbt_run_template_docs_update

on:
  workflow_call:
    inputs:
      resource_id:
        description: 'The resource ID to refresh (defaults to repository name)'
        required: false
        type: string
        default: ''
      api_url_stg:
        description: 'The DDS API URL for staging'
        required: false
        type: string
        default: 'https://dds-api.fsc-data-platform-stg.io'
      api_url_prod:
        description: 'The DDS API URL for production'
        required: false
        type: string
        default: 'https://dds-api.fsc-data-platform.io'
      force_refresh:
        description: 'Force refresh the cache'
        required: false
        type: boolean
        default: true
    secrets:
      PASSWORD:
        required: true
      SLACK_WEBHOOK_URL:
        required: false
      DDS_STG_API_KEY:
        description: 'The DDS API key for staging'
        required: true
      DDS_PROD_API_KEY:
        description: 'The DDS API key for production'
        required: true
          
jobs:
  run_dbt_jobs_refresh:
    runs-on: ubuntu-latest
    environment:
      name: workflow_secrets

    steps:
      - uses: actions/checkout@v3
      
      - name: Extract project & profile names from dbt_project.yml
        id: project-name
        run: |
          PROFILE_NAME=$(grep "^profile:" dbt_project.yml | sed 's/^profile:[[:space:]]*"//' | sed 's/".*$//')
          PROJECT_NAME=$(grep "^name:" dbt_project.yml | sed 's/^name:[[:space:]]*"//' | sed 's/".*$//')
          echo "PROFILE_NAME=$PROFILE_NAME" >> $GITHUB_ENV
          echo "PROJECT_NAME=$PROJECT_NAME" >> $GITHUB_ENV
          echo "PROFILE_NAME: $PROFILE_NAME"
          echo "PROJECT_NAME: $PROJECT_NAME"
      
      - name: Set production environment variables
        run: |
          echo "TARGET=prod" >> $GITHUB_ENV
          echo "ACCOUNT=vna27887.us-east-1" >> $GITHUB_ENV
          echo "REGION=us-east-1" >> $GITHUB_ENV
          echo "SCHEMA=ADMIN" >> $GITHUB_ENV
          echo "DATABASE=$PROFILE_NAME" >> $GITHUB_ENV
          echo "ROLE=DBT_CLOUD_$PROFILE_NAME" >> $GITHUB_ENV
          echo "USER=DBT_CLOUD_$PROFILE_NAME" >> $GITHUB_ENV
          echo "WAREHOUSE=DBT_CLOUD" >> $GITHUB_ENV
          echo "PASSWORD=${{ secrets.PASSWORD }}" >> $GITHUB_ENV

      - uses: actions/setup-python@v4
        with:
          python-version: "3.10"
          cache: "pip"

      - name: Install dependencies
        run: |
          pip install -r requirements.txt
          dbt deps
      
      - name: deploy seed files
        run: |
          dbt seed -t prod

      - name: checkout docs branch
        run: |
          git checkout -B docs origin/main

      - name: generate dbt docs
        run: dbt docs generate -t prod --exclude "fsc_evm,tag:streamline" "fsc_evm,tag:scores"

      - name: move files to docs directory
        run: |
          mkdir -p ./docs
          cp target/{catalog.json,manifest.json,index.html} docs/

      - name: clean up target directory
        run: dbt clean

      - name: check for changes
        run: git status

      - name: stage changed files
        run: git add .

      - name: commit changed files
        run: |
          git config user.email "abc@xyz"
          git config user.name "github-actions"
          git commit -am "Auto-update docs"

      - name: push changes to docs
        run: |
          git push -f --set-upstream origin docs

  refresh-cache:
    needs: [run_dbt_jobs_refresh]
    runs-on: ubuntu-latest
    environment: workflow_secrets
    strategy:
      matrix:
        environment:
          - name: staging
            url_input: api_url_stg
            secret_key: DDS_STG_API_KEY
          - name: production
            url_input: api_url_prod
            secret_key: DDS_PROD_API_KEY
    steps:
    - name: Refresh cache (${{ matrix.environment.name }})
      shell: bash
      env:
        API_URL: ${{ matrix.environment.url_input == 'api_url_stg' && inputs.api_url_stg || inputs.api_url_prod }}
        API_KEY: ${{ matrix.environment.secret_key == 'DDS_STG_API_KEY' && secrets.DDS_STG_API_KEY || secrets.DDS_PROD_API_KEY }}
        ENV_NAME: ${{ matrix.environment.name }}
      run: |
        RESOURCE_ID="${{ inputs.resource_id || github.event.repository.name }}"
        FORCE_PARAM="${{ inputs.force_refresh && '&force=true' || '' }}"
        
        echo "üîÑ Refreshing ${ENV_NAME^^} cache for resource: $RESOURCE_ID"
        echo "API URL: $API_URL"
        
        # Make the API call and capture both response and HTTP status
        RESPONSE=$(curl -s -w "\n%{http_code}" -X POST "$API_URL/api/v1/cache/refresh?resource_id=$RESOURCE_ID$FORCE_PARAM" \
          -H "X-API-Key: $API_KEY" \
          -H "Content-Type: application/json")
        
        # Split response and status code
        HTTP_STATUS=$(echo "$RESPONSE" | tail -n1)
        RESPONSE_BODY=$(echo "$RESPONSE" | head -n -1)
        
        echo "HTTP Status: $HTTP_STATUS"
        echo "Response: $RESPONSE_BODY"
        
        # Check for success
        if [ "$HTTP_STATUS" -eq 200 ]; then
          # Check if response indicates success
          if echo "$RESPONSE_BODY" | grep -q '"success":true'; then
            echo ""
            echo "‚úÖ ${ENV_NAME^^} cache refresh initiated successfully!"
            echo "üìä Resource: $RESOURCE_ID"
            
            # Extract and display key information from the response
            MESSAGE=$(echo "$RESPONSE_BODY" | grep -o '"message":"[^"]*"' | sed 's/"message":"//;s/"//')
            if [ -n "$MESSAGE" ]; then
              echo "üìù Message: $MESSAGE"
            fi
            
            # Check for async job response
            JOB_ID=$(echo "$RESPONSE_BODY" | grep -o '"job_id":"[^"]*"' | sed 's/"job_id":"//;s/"//')
            JOB_STATUS=$(echo "$RESPONSE_BODY" | grep -o '"status":"[^"]*"' | sed 's/"status":"//;s/"//')
            
            if [ -n "$JOB_ID" ]; then
              echo "üîñ Job ID: $JOB_ID"
              echo "‚è≥ Status: $JOB_STATUS"
              echo "üí° Check status at: $API_URL/api/v1/cache/jobs?job_id=$JOB_ID"
            fi
            
            # Extract discovery summary if available (legacy synchronous format)
            TOTAL_DISCOVERED=$(echo "$RESPONSE_BODY" | grep -o '"total_discovered":[0-9]*' | grep -o '[0-9]*' || true)
            PROJECTS_WITH_DOCS=$(echo "$RESPONSE_BODY" | grep -o '"projects_with_docs":[0-9]*' | grep -o '[0-9]*' || true)
            PROJECTS_WITHOUT_DOCS=$(echo "$RESPONSE_BODY" | grep -o '"projects_without_docs":[0-9]*' | grep -o '[0-9]*' || true)
            
            if [ -n "$TOTAL_DISCOVERED" ]; then
              echo "üîç Discovery Summary:"
              echo "   ‚Ä¢ Total repositories discovered: $TOTAL_DISCOVERED"
              echo "   ‚Ä¢ Projects with docs: $PROJECTS_WITH_DOCS"
              echo "   ‚Ä¢ Projects without docs: $PROJECTS_WITHOUT_DOCS"
            fi
            
            echo ""
          else
            echo "‚ùå ${ENV_NAME^^} API returned error: $RESPONSE_BODY"
            exit 1
          fi
        else
          echo "‚ùå ${ENV_NAME^^} HTTP request failed with status $HTTP_STATUS"
          echo "Response: $RESPONSE_BODY"
          exit 1
        fi

  notify-failure:
    needs: [run_dbt_jobs_refresh, refresh-cache]
    if: failure()
    uses: ./.github/workflows/slack_notify.yml
    secrets:
      SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}